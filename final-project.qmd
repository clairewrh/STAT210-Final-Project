---
title: "Final Project"
authors: Claire Wang & Xeno Hu
---
### Introduction
Cardiovascular diseases (CVDs) are the leading cause of death in the United States, with one person dying of the disease every 34 seconds (Centers for Disease Control and Prevention, 2022). Previous research has highlighted male gender, old age, obesity, abnormal cholesterol and fasting blood glucose as important predictors for CVDs, among many others (Damen et al., 2016).

As CVD incidence continues to soar, the need for an effective predictive model cannot be overstated. Such a model could enable doctors to take preventive measures, treat patients early, or encourage individuals at high risk to adopt lifestyle changes. In this report, we aim to construct a predictive model based on the "Heart Failure Prediction Dataset" by assessing the 11 possible predictors (including chest pain type, resting blood pressure, cholesterol levels, maximum heart rate, resting ECG measurements, etc.). By doing so, we seek to enhance the scientific community's understanding of CVDs and their associated risk factors, ultimately contributing to better prevention, early identification, and management of this critical disease for both individuals and populations.

## Data Description

This “Heart Failure Prediction Dataset” includes 11 characteristics that can be utilized to anticipate the potential risk of a CVD; it is called “Heart Failure Prediction Dataset” because it is not uncommon for a CVD to lead to heart failure (Velagaleti et al., 2007). The dataset was formed by merging five heart-related datasets (the Cleveland, Hungarian, Switzerland, Long Beach VA, and Stalog Heart Dataset) based on 11 common features. This dataset is currently the largest available heart disease dataset for research purposes, consisting of 918 observations.

Source: https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction


```{r loading packages and data, messages = F, warning = F}
library(tidyverse)
library(tidymodels)
library(glmnet)
library(MASS)
library(leaps)
library(dplyr)
library(broom)
library(ggplot2)
library(UpSetR)
library(naniar)
data = read_csv("heart2.csv")
```

Source: https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset


## EDA
```{r check missingness}
vis_miss(data)
```
At first glance, there seems to be no missingness in the dataset. 

Upon closer examination, we discovered that 173 out of the 919 observations had a serum cholesterol level of 0 mm/dl. Since this is physiologically impossible, we concluded that these observations were actually missing cholesterol data. This meant that our dataset had missing values after all.

We decide to use complete case analysis because it is relatively easy to implement, and it can reduce bias in the estimates of the variable of interest when the missing data are missing completely at random or missing at random. Although a complete case analysis in this case would lead to a 20% sample loss, we believe that it is better than imputation because our current knowledge does not allow accurate prediction of cholesterol levels of these observations.

```{r drop cholesterol}
data$Cholesterol [data$Cholesterol ==0] <- NA
data_new <- subset(data) %>%
  drop_na()
```


```{r cvd-distribution}
ggplot(data = data_new, aes(x = HeartDisease)) +
  geom_histogram(binwidth = 0.5) 
  labs(title = "Distribution of CVD",
       subtitle = "Among Patients",
       x = "Presence of CVD",
       y = "Count")
```
The distribution of CVD in our data appears to be relatively evenly distributed between patients with and without the disease. This suggests that there are sufficient data available for both categories of the response variable to perform further statistical analysis and develop a predictive model.

Previous research has identified age, resting blood pressure, serum cholesterol, the presence of exercise-induced angina, and maximum heart rate as indicators of the presence of heart disease (Hajar, 2017). In addition, the type of chest pain (cp) is a significant factor in distinguishing between types of CVD. Therefore, we will include cp as a categorical predictor variable and conduct more exploratory data analysis on all these variables.


```{r age}
data_summary <- data_new %>%
  group_by(HeartDisease) %>%
  summarise(mean = mean(Age),
            median = median(Age),
            sd = sd(Age),
            IQR = IQR(Age))
data_summary
```
```{r table for sex }
freq_table <- table(Sex = data_new$Sex, HeartDisease = data_new$HeartDisease)
freq_table_tibble <- as_tibble(freq_table)
colnames(freq_table_tibble) <- c("Sex", "No Heart Disease", "Heart Disease")
freq_table_tibble
```

```{r box plot for age }
ggplot(data_new, aes(x = Age, y = HeartDisease, group = HeartDisease)) + 
  geom_boxplot() +
  labs(title = "Age vs. Presence of CVD",
       x = "Age",
       y = "Presence of CVD") +
  theme_bw()
```


```{r box plot for cholesterol}
ggplot(data_new, aes(x = Cholesterol, y = HeartDisease, group = HeartDisease)) +  
  geom_boxplot() +
  labs(title = "Cholesterol Distribution vs. Presence of CVD",
       x = "Serum cholestoral in mg/dl",
       y = "Presence of CVD") +
  theme_bw()
```

```{r box plot for resting blood pressure}
ggplot(data_new, aes(x = RestingBP, y = HeartDisease, group = HeartDisease)) + 
  geom_boxplot() +
  labs(title = "Resting Blood Pressure vs. Presence of CVD",
       x = "Resting blood pressure (in mm Hg on admission to the hospital)",
       y = "Presence of CVD") +
  theme_bw()
```

```{r box plot for max hr}
ggplot(data_new, aes(x = MaxHR, y = HeartDisease, group = HeartDisease)) +  
  geom_boxplot() +
  labs(title = "Maximum Heart Rate vs. Presence of CVD",
       x = "Maximum heart rate achieved",
       y = "Presence of CVD") +
  theme_bw()
```

```{r proportion plot for exercise angina}
data_prop <- data_new %>% 
  group_by(ExerciseAngina, HeartDisease) %>%
  summarise(Freq = n()) %>%
  mutate(Prop = Freq / sum(Freq))
ggplot(data_prop, aes(x = ExerciseAngina, y = Prop, fill = factor(HeartDisease))) +
  geom_col(position = "dodge") +
  scale_fill_manual(values = c("#619CFF", "#FF6B5B"), labels = c("No Heart Disease", "Heart Disease")) +
  labs(x = "Presence of Exercise-induced Angina", y = "Proportion") +
  ggtitle("Presence of Exercise-induced Angina vs. Presence of CVD") +
  theme_bw()

```
```{r proportion plot for sex}
data_props <- data_new %>% 
  group_by(Sex, HeartDisease) %>%
  summarise(Freq = n()) %>%
  mutate(Prop = Freq / sum(Freq))
ggplot(data_props, aes(x = Sex, y = Prop, fill = factor(HeartDisease))) +
  geom_col(position = "dodge") +
  scale_fill_manual(values = c("#619CFF", "#FF6B5B"), labels = c("No Heart Disease", "Heart Disease")) +
  labs(x = "Sex", y = "Proportion") +
  ggtitle("Sex vs. Presence of CVD") +
  theme_bw()

```

## Methodology
This section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.

Grading criteria
The analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to select the final model; the approach is clearly described in the report. The model selection process was reasonable, and addressed any violations in model conditions were discussed and/or fixed. The model conditions and diagnostics are thoroughly and accurately assessed for their model. If violations of model conditions are still present, there was a reasonable attempt to address the violations based on the course content.


Using LASSO for variable selection
```{r var-select, message = F, warning = F}
y <- data_new$HeartDisease
x <- model.matrix(HeartDisease ~ ., data = data)
m_lasso_cv <- cv.glmnet(x, y, alpha = 1)
best_lambda <- m_lasso_cv$lambda.min
m_best <- glmnet(x, y, alpha = 1, lambda = best_lambda)
m_best$beta
summary(m_best)
```

Using stepwise method for variable selection
```{r stepwise}
m_none <- lm(HeartDisease ~ 1, data = data_new)
m_all <- lm(HeartDisease ~ ., 
            data = data)
stepAIC(m_none, 
        scope = list(lower = m_none, upper = m_all),
        data = data, direction = "both")
```

Using all subset selection (not sure if nvmax should be set to 15)
```{r all subset}
m_all <- regsubsets(HeartDisease ~ .,
                  data = data_new,
                  nbest = 1, nvmax = 15)
summary(m_all)
summary(m_all)$cp
```

Notes:

Why all subset? Maybe all of the predictors seem to make sense, we don't want to select manually based on literature

 #11 has the lowest CP score (need to explain what cp means!and why we select based on cp score)
11: Age, sex, chest pain, resting bp, fasting bs, exercise angina, old peak, ST slope.

Need to figure out what old peak means, explain exercise angina, and ST slope.

### Model attempts
```{r logistic regression using #11 from all subset}
m1 <- glm(HeartDisease ~ Age + Sex + ChestPainType + RestingBP + FastingBS + 
            ExerciseAngina + Oldpeak + ST_Slope, 
          data = data_new,
          family = "binomial")
tidy(m1)
m1_aug <- augment(m1)
```

Using a 0.05 significance level, it looks like the p-values of FastingBS & RestingBP are insignificant. Take these two predictors out:

```{r logistic regression using from all subset}
m2 <- glm(HeartDisease ~ Age + Sex + ChestPainType + ExerciseAngina + 
            Oldpeak + ST_Slope, 
          data = data_new,
          family = "binomial")
tidy(m2)
m2_aug <- augment(m2)
```

```{r logistic regression using all predictors}
m3 <- glm(HeartDisease ~ ., 
          data = data_new,
          family = "binomial")
tidy(m3)
m3_aug <- augment(m3)
```

``` {r ROC curve for model m1}

m1_aug <- m1_aug %>% 
  mutate(prob = exp(.fitted)/(1 + exp(.fitted)),
         pred_leg = ifelse(prob > 0.5, "Heart Disease", "No Heart Disease")) %>% 
  dplyr::select(.fitted, prob, pred_leg, HeartDisease)

m1_aug %>% 
  roc_curve(
    truth = as.factor(HeartDisease),
    prob, 
    event_level = "second"
  ) %>% 
  autoplot()

m1_aug %>% 
  roc_auc(
    truth = as.factor(HeartDisease),
    prob, 
    event_level = "second"
  )

table(m1_aug $pred_leg, m1_aug $HeartDisease)
``` 

``` {r ROC curve for model m2}

m2_aug <- m2_aug %>% 
  mutate(prob = exp(.fitted)/(1 + exp(.fitted)),
         pred_leg = ifelse(prob > 0.5, "Heart Disease", "No Heart Disease")) %>% 
  dplyr::select(.fitted, prob, pred_leg, HeartDisease)

m2_aug %>% 
  roc_curve(
    truth = as.factor(HeartDisease),
    prob, 
    event_level = "second"
  ) %>% 
  autoplot()

m2_aug %>% 
  roc_auc(
    truth = as.factor(HeartDisease),
    prob, 
    event_level = "second"
  )

table(m2_aug $pred_leg, m2_aug $HeartDisease)
``` 

``` {r ROC curve for model m3}

m3_aug <- m3_aug %>% 
  mutate(prob = exp(.fitted)/(1 + exp(.fitted)),
         pred_leg = ifelse(prob > 0.5, "Heart Disease", "No Heart Disease")) %>% 
  dplyr::select(.fitted, prob, pred_leg, HeartDisease)

m3_aug %>% 
  roc_curve(
    truth = as.factor(HeartDisease),
    prob, 
    event_level = "second"
  ) %>% 
  autoplot()

m3_aug %>% 
  roc_auc(
    truth = as.factor(HeartDisease),
    prob, 
    event_level = "second"
  )
``` 

## Results
This is where you will output the final model with any relevant model fit statistics. Describe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.

Grading criteria
The model fit is clearly assessed, and interesting findings from the model are clearly described. Interpretations of model coefficients are used to support the key findings and conclusions, rather than merely listing the interpretation of every model coefficient. If the primary modeling objective is prediction, the model’s predictive power is thoroughly assessed.

## Discussion
In this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.

Grading criteria
Overall conclusions from analysis are clearly described, and the model results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.

Citations: 
Centers for Disease Control and Prevention, National Center for Health Statistics. About Multiple Cause of Death, 1999–2020. CDC WONDER Online Database website. Atlanta, GA: Centers for Disease Control and Prevention; 2022. Accessed May 1, 2023.

Damen, J. A., Hooft, L., Schuit, E., Debray, T. P., Collins, G. S., Tzoulaki, I., Lassale, C. M., Siontis, G. C., Chiocchia, V., Roberts, C., Schlüssel, M. M., Gerry, S., Black, J. A., Heus, P., van der Schouw, Y. T., Peelen, L. M., & Moons, K. G. (2016). Prediction models for cardiovascular disease risk in the general population: systematic review. BMJ (Clinical research ed.), 353, i2416. https://doi.org/10.1136/bmj.i2416

Fedesoriano. (September 2021). Heart Failure Prediction Dataset. Retrieved [May 2, 2023] from https://www.kaggle.com/fedesoriano/heart-failure-prediction.

Velagaleti, R. S., & Vasan, R. S. (2007). Heart failure in the twenty-first century: is it a coronary artery disease or hypertension problem?. Cardiology clinics, 25(4), 487–v. https://doi.org/10.1016/j.ccl.2007.08.010