---
title: "Final Project"
authors: Claire Wang & Xeno Hu
---
### Introduction
Cardiovascular diseases (CVDs) are the leading cause of death in the United States, with one person dying of the disease every 34 seconds (Centers for Disease Control and Prevention, 2022). Previous research has highlighted male gender, old age, obesity, abnormal cholesterol and fasting blood glucose as important predictors for CVDs, among many others (Damen et. al., 2016).

As CVD incidence continues to soar, the need for an effective predictive model cannot be overstated. Such a model could enable doctors to take preventive measures, treat patients early, or encourage individuals at high risk to adopt lifestyle changes. In this report, we aim to construct a predictive model based on the "Heart Diseases" dataset, by assessing the 13 possible predictors (including chest pain type, blood pressure, cholesterol levels, fasting blood sugar, resting ECG measurements, etc.). By doing so, we seek to enhance the scientific community's understanding of CVDs and their associated risk factors, ultimately contributing to better prevention and management of this critical disease for both individuals and populations.

## Data Description

```{r loading packages and data, messages = F, warning = F}
library(tidyverse)
library(tidymodels)
library(glmnet)
library(MASS)
library(leaps)
library(dplyr)
library(ggplot2)
library(UpSetR)
library(naniar)
data = read_csv("heart2.csv")
```

Source: https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset

This dataset contains information about patients who were suspected to have heart disease. The dataset contains 1026 patients, each described by 14 features. These features include demographic information such as age, sex, and chest pain type, clinical variables such as blood pressure, cholesterol levels, and heart rate, and laboratory variables such as results from electrocardiogram (ECG) tests and exercise stress tests. It was formed by researchers at the Cleveland Clinic Foundation in 1988 by compiling data from medical records from Cleveland, Hungary, Switzerland, and Long Beach V. The "target" variable is what we are trying to predict; it is binary, indicating the presence or absence of heart disease with 0 and 1, respectively.

Centers for Disease Control and Prevention, National Center for Health Statistics. About Multiple Cause of Death, 1999–2020. CDC WONDER Online Database website. Atlanta, GA: Centers for Disease Control and Prevention; 2022. Accessed February 21, 2022.

Damen, J. A., Hooft, L., Schuit, E., Debray, T. P., Collins, G. S., Tzoulaki, I., Lassale, C. M., Siontis, G. C., Chiocchia, V., Roberts, C., Schlüssel, M. M., Gerry, S., Black, J. A., Heus, P., van der Schouw, Y. T., Peelen, L. M., & Moons, K. G. (2016). Prediction models for cardiovascular disease risk in the general population: systematic review. BMJ (Clinical research ed.), 353, i2416. https://doi.org/10.1136/bmj.i2416

## EDA
```{r check missingness}
vis_miss(data)
```
At first glance, there seems to be no missingness in the dataset. 

Upon closer examination, we discovered that 173 out of the 919 observations had a serum cholesterol level of 0 mm/dl. Since this is physiologically impossible, we concluded that these observations were actually missing cholesterol data. This meant that our dataset had missing values after all.

We decide to use complete case analysis because it is relatively easy to implement, and it can reduce bias in the estimates of the variable of interest when the missing data are missing completely at random or missing at random. Although a complete case analysis in this case would lead to a 20% sample loss, we believe that it is better than imputation because our current knowledge does not allow accurate prediction of cholesterol levels of these observations.

```{r drop cholesterol}
data$Cholesterol [data$Cholesterol ==0] <- NA
data_new <- subset(data) %>%
  drop_na()
```


```{r summarizing-the-means}
data_new%>%
  summarize(mean_age = mean(Age),
            mean_chol = mean(Cholesterol),
            mean_trestbps = mean(RestingBP),
            mean_thalach = mean(MaxHR)) %>%
  as_tibble()
```

```{r cvd-distribution}
ggplot(data = data_new, aes(x = HeartDisease)) +
  geom_histogram(binwidth = 0.5) 
  labs(title = "Distribution of CVD",
       subtitle = "Among Patients",
       x = "Presence of CVD",
       y = "Count")
```
The distribution of CVD in our data appears to be relatively evenly distributed between patients with and without the disease. This means that there are sufficient data available for both categories of the response variable to perform further statistical analysis and develop a predictive model.

Previous research has identified age, resting blood pressure, serum cholesterol, the presence of exercise-induced angina, and maximum heart rate as indicators of the presence of heart disease (Hajar, 2017). In addition, the type of chest pain (cp) is a significant factor in distinguishing between types of CVD. Therefore, we will include cp as a categorical predictor variable and conduct more exploratory data analysis on all these variables.


```{r age}
data_summary <- data_new %>%
  group_by(HeartDisease) %>%
  summarise(mean = mean(Age),
            median = median(Age),
            sd = sd(Age),
            IQR = IQR(Age))
data_summary
```
```{r table for sex }
freq_table <- table(Sex = data_new$Sex, HeartDisease = data_new$HeartDisease)
freq_table_tibble <- as_tibble(freq_table)
colnames(freq_table_tibble) <- c("Sex", "No Heart Disease", "Heart Disease")
freq_table_tibble
```

```{r box plot for age }
ggplot(data_new, aes(x = Age, y = HeartDisease, group = HeartDisease)) + 
  geom_boxplot() +
  labs(title = "Age vs. Presence of CVD",
       x = "Age",
       y = "Presence of CVD") +
  theme_bw()
```


```{r box plot for cholesterol}
ggplot(data_new, aes(x = Cholesterol, y = HeartDisease, group = HeartDisease)) +  
  geom_boxplot() +
  labs(title = "Cholesterol Distribution vs. Presence of CVD",
       x = "Serum cholestoral in mg/dl",
       y = "Presence of CVD") +
  theme_bw()
```

```{r box plot for resting blood pressure}
ggplot(data_new, aes(x = RestingBP, y = HeartDisease, group = HeartDisease)) + 
  geom_boxplot() +
  labs(title = "Resting Blood Pressure vs. Presence of CVD",
       x = "Resting blood pressure (in mm Hg on admission to the hospital)",
       y = "Presence of CVD") +
  theme_bw()
```

```{r box plot for max hr}
ggplot(data_new, aes(x = MaxHR, y = HeartDisease, group = HeartDisease)) +  
  geom_boxplot() +
  labs(title = "Maximum Heart Rate vs. Presence of CVD",
       x = "Maximum heart rate achieved",
       y = "Presence of CVD") +
  theme_bw()
```

## Methodology
This section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.

Grading criteria
The analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to select the final model; the approach is clearly described in the report. The model selection process was reasonable, and addressed any violations in model conditions were discussed and/or fixed. The model conditions and diagnostics are thoroughly and accurately assessed for their model. If violations of model conditions are still present, there was a reasonable attempt to address the violations based on the course content.



Using LASSO for variable selection
```{r var-select, message = F, warning = F}
y <- data$HeartDisease
x <- model.matrix(HeartDisease ~ ., data = data)
m_lasso_cv <- cv.glmnet(x, y, alpha = 1)
best_lambda <- m_lasso_cv$lambda.min
m_best <- glmnet(x, y, alpha = 1, lambda = best_lambda)
m_best$beta
summary(m_best)
```

Using stepwise method for variable selection
```{r stepwise}
m_none <- lm(HeartDisease ~ 1, data = data)
m_all <- lm(HeartDisease ~ ., 
            data = data)
stepAIC(m_none, 
        scope = list(lower = m_none, upper = m_all),
        data = data, direction = "both")
```

Using all subset selection
```{r all subset}
m_all <- regsubsets(HeartDisease ~ .,
                  data = data, 
                  nbest = 1, nvmax = 11)
summary(m_all)
```

## Results
This is where you will output the final model with any relevant model fit statistics. Describe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.

Grading criteria
The model fit is clearly assessed, and interesting findings from the model are clearly described. Interpretations of model coefficients are used to support the key findings and conclusions, rather than merely listing the interpretation of every model coefficient. If the primary modeling objective is prediction, the model’s predictive power is thoroughly assessed.

## Discussion
In this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.

Grading criteria
Overall conclusions from analysis are clearly described, and the model results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.